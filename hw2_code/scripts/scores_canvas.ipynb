{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/python\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import scipy\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import random\n",
    "import copy\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "#m_trn_file_path = \"../cnn_bow/cnn_trn.csv\"\n",
    "#m_val_file_path = \"../cnn_bow/cnn_val.csv\"\n",
    "#m_test_file_path = \"../cnn_bow/cnn_test.csv\"\n",
    "\n",
    "m_trn_file_path = \"../surf_bow/surf_1000_trn.csv\"\n",
    "m_val_file_path = \"../surf_bow/surf_1000_val.csv\"\n",
    "m_test_file_path = \"../surf_bow/surf_1000_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a_train_df = pd.read_csv(a_trn_file_path, index_col='Unnamed: 0')\n",
    "#a_train_df.drop(['target', 'name'], axis=1, inplace=True)\n",
    "\n",
    "m_train_df = pd.read_csv(m_trn_file_path, index_col='Unnamed: 0')\n",
    "m_train_df.drop(['name'], axis=1, inplace=True)\n",
    "\n",
    "train_df = m_train_df\n",
    "train_df.target.fillna('P000', inplace=True)\n",
    "train_df.fillna(0.0, inplace=True)\n",
    "\n",
    "### tf_idf conversion\n",
    "\n",
    "# 1. Save target column, and drop if from dataframe\n",
    "train_df_target = pd.DataFrame(train_df['target'], columns=['target'])\n",
    "train_df.drop(['target'], axis=1, inplace=True )\n",
    "\n",
    "# 2. Replace frequencies with tf_idf scores\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(train_df)\n",
    "X_train_tf = tf_transformer.transform(train_df)\n",
    "train_df = pd.DataFrame(X_train_tf.todense(), columns=train_df.columns.values)\n",
    "\n",
    "# 3. Add back the target column\n",
    "train_df = pd.concat([train_df, train_df_target], axis=1)\n",
    "\n",
    "#a_test_df = pd.read_csv(a_val_file_path, index_col='Unnamed: 0')\n",
    "#a_test_df.drop(['target', 'name'], axis=1, inplace=True)\n",
    "m_test_df = pd.read_csv(m_val_file_path, index_col='Unnamed: 0')\n",
    "m_test_df.drop(['name'], axis=1, inplace=True )\n",
    "#test_df = pd.concat([a_test_df, m_test_df], axis=1)\n",
    "\n",
    "test_df = m_test_df\n",
    "test_df.target.fillna('P000', inplace=True)\n",
    "test_df.fillna(0.0, inplace=True)\n",
    "\n",
    "### tf_idf conversion\n",
    "\n",
    "# 1. Save target column, and drop if from dataframe\n",
    "test_df_target = pd.DataFrame(test_df['target'], columns=['target'])\n",
    "test_df.drop(['target'], axis=1, inplace=True )\n",
    "\n",
    "# 2. Replace frequencies with tf_idf scores\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(test_df)\n",
    "X_train_tf = tf_transformer.transform(test_df)\n",
    "test_df = pd.DataFrame(X_train_tf.todense(), columns=test_df.columns.values)\n",
    "\n",
    "# 3. Add back the target column\n",
    "test_df = pd.concat([test_df, test_df_target], axis=1)\n",
    "\n",
    "# Machine Learning\n",
    "prediction_var = list(train_df.columns)\n",
    "prediction_var.remove('target')\n",
    "#prediction_var.remove('name')\n",
    "\n",
    "# Get input training data\n",
    "train_X = train_df[prediction_var]\n",
    "\n",
    "# Get input target variable\n",
    "train_y = train_df.target\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning\n",
    "prediction_var = list(test_df.columns)\n",
    "prediction_var.remove('target')\n",
    "\n",
    "# Get test data feature\n",
    "test_X = test_df[prediction_var]\n",
    "\n",
    "# Get test data target\n",
    "test_y = test_df.target\n",
    "\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weight='balanced',decision_function_shape = 'ovr',\n",
    "\n",
    "dict_weights = {'P000':0.0000001, 'P001': 29, 'P002': 14, 'P003':34}\n",
    "\n",
    "clf = svm.SVC(gamma='scale', probability=True, class_weight=dict_weights,decision_function_shape = 'ovr')\n",
    "\n",
    "# Fit the model to training\n",
    "clf.fit(train_X,train_y)\n",
    "\n",
    "# Check prediction accuracy\n",
    "prediction = clf.decision_function(test_X)\n",
    "\n",
    "prob_list = prediction[:,1]\n",
    "x = np.array([test_y == 'P001'][0]).astype(int)\n",
    "print('P001 &', round(average_precision_score(x,prob_list, pos_label=1),4))\n",
    "\n",
    "prob_list = prediction[:,2]\n",
    "x = np.array([test_y == 'P002'][0]).astype(int)\n",
    "print('P002 &', round(average_precision_score(x,prob_list, pos_label=1),4))\n",
    "\n",
    "prob_list = prediction[:,3]\n",
    "x = np.array([test_y == 'P003'][0]).astype(int)\n",
    "print('P003 &', round(average_precision_score(x,prob_list, pos_label=1),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on validation also, for the Canvas submission\n",
    "\n",
    "m_train_df = pd.read_csv(m_trn_file_path, index_col='Unnamed: 0')\n",
    "m_train_df.drop(['name'], axis=1, inplace=True)\n",
    "\n",
    "m_test_df = pd.read_csv(m_val_file_path, index_col='Unnamed: 0')\n",
    "m_test_df.drop(['name'], axis=1, inplace=True )\n",
    "\n",
    "train_df = m_train_df\n",
    "train_df.target.fillna('P000', inplace=True)\n",
    "train_df.fillna(0.0, inplace=True)\n",
    "\n",
    "test_df = m_test_df\n",
    "test_df.target.fillna('P000', inplace=True)\n",
    "test_df.fillna(0.0, inplace=True)\n",
    "\n",
    "train_df = train_df.append(test_df, ignore_index=True)\n",
    "\n",
    "### tf_idf conversion\n",
    "\n",
    "# 1. Save target column, and drop if from dataframe\n",
    "train_df_target = pd.DataFrame(train_df['target'], columns=['target'])\n",
    "train_df.drop(['target'], axis=1, inplace=True )\n",
    "\n",
    "# 2. Replace frequencies with tf_idf scores\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(train_df)\n",
    "X_train_tf = tf_transformer.transform(train_df)\n",
    "train_df = pd.DataFrame(X_train_tf.todense(), columns=train_df.columns.values)\n",
    "\n",
    "# 3. Add back the target column\n",
    "train_df = pd.concat([train_df, train_df_target], axis=1)\n",
    "\n",
    "# Get input training data\n",
    "train_X = train_df[prediction_var]\n",
    "\n",
    "# Get input target variable\n",
    "train_y = train_df.target\n",
    "\n",
    "m_test_df = pd.read_csv(m_test_file_path, index_col='Unnamed: 0')\n",
    "\n",
    "name_list = m_test_df['name']\n",
    "\n",
    "m_test_df.drop(['name'], axis=1, inplace=True )\n",
    "\n",
    "test_df = m_test_df\n",
    "test_df.target.fillna('P000', inplace=True)\n",
    "test_df.fillna(0.0, inplace=True)\n",
    "\n",
    "# Machine Learning\n",
    "prediction_var = list(test_df.columns)\n",
    "prediction_var.remove('target')\n",
    "\n",
    "# Get test data features\n",
    "test_X = test_df[prediction_var]\n",
    "\n",
    "# Get test data target\n",
    "test_y = test_df.target\n",
    "\n",
    "clf = svm.SVC(gamma='scale', probability=True, class_weight=dict_weights,decision_function_shape = 'ovr')\n",
    "\n",
    "# Fit the model to training\n",
    "clf.fit(train_X,train_y)\n",
    "\n",
    "with open(\"../../all_test.video\", \"r\") as f:\n",
    "    video_list = f.readlines()\n",
    "\n",
    "# Check prediction accuracy\n",
    "prediction = clf.decision_function(test_X)\n",
    "\n",
    "prob_list = prediction[:,1]\n",
    "\n",
    "output_df = pd.DataFrame({\"VideoID\":name_list, \"Label\":prob_list})\n",
    "output_df = output_df.set_index('VideoID')\n",
    "dict1 = output_df.to_dict('index')\n",
    "res = []\n",
    "\n",
    "for line in video_list:\n",
    "    vid = line.strip(\"\\n\")\n",
    "    if(vid in dict1):\n",
    "        res.append(dict1[vid]['Label'])\n",
    "    else:\n",
    "        res.append(0.0)\n",
    "\n",
    "res = pd.DataFrame(res, columns=None)\n",
    "res.to_csv(path_or_buf=\"../scores/\" + str('P001')+\"_surf.lst\", index=False)\n",
    "\n",
    "prob_list = prediction[:,2]\n",
    "output_df = pd.DataFrame({\"VideoID\":name_list, \"Label\":prob_list})\n",
    "output_df = output_df.set_index('VideoID')\n",
    "dict1 = output_df.to_dict('index')\n",
    "res = []\n",
    "\n",
    "for line in video_list:\n",
    "    vid = line.strip(\"\\n\")\n",
    "    if(vid in dict1):\n",
    "        res.append(dict1[vid]['Label'])\n",
    "    else:\n",
    "        res.append(0.0)\n",
    "\n",
    "res = pd.DataFrame(res, columns=None)\n",
    "res.to_csv(path_or_buf=\"../scores/\" + str('P002')+\"_surf.lst\", index=False)\n",
    "\n",
    "prob_list = prediction[:,3]\n",
    "output_df = pd.DataFrame({\"VideoID\":name_list, \"Label\":prob_list})\n",
    "output_df = output_df.set_index('VideoID')\n",
    "dict1 = output_df.to_dict('index')\n",
    "res = []\n",
    "\n",
    "for line in video_list:\n",
    "    vid = line.strip(\"\\n\")\n",
    "    if(vid in dict1):\n",
    "        res.append(dict1[vid]['Label'])\n",
    "    else:\n",
    "        res.append(0.0)\n",
    "\n",
    "res = pd.DataFrame(res, columns=None)\n",
    "res.to_csv(path_or_buf=\"../scores/\" + str('P003')+\"_surf.lst\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
