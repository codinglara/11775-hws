{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/python\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import scipy\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import random\n",
    "import copy\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "s_trn_file_path = \"../surf_bow/surf_400_trn.csv\"\n",
    "s_val_file_path = \"../surf_bow/surf_400_val.csv\"\n",
    "s_test_file_path = \"../surf_bow/surf_400_test.csv\"\n",
    "\n",
    "#s_trn_file_path = \"../cnn_bow/cnn_trn.csv\"\n",
    "#s_val_file_path = \"../cnn_bow/cnn_val.csv\"\n",
    "#s_test_file_path = \"../cnn_bow/cnn_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(834, 400)\n",
      "         S0        S1        S2        S3        S4        S5        S6  \\\n",
      "0  0.001223  0.001459  0.027367  0.018513  0.003287  0.001316  0.138583   \n",
      "1  0.014347  0.003422  0.047592  0.063718  0.029106  0.010969  0.062388   \n",
      "2  0.011718  0.006722  0.039280  0.019939  0.023727  0.010915  0.178425   \n",
      "3  0.086588  0.002020  0.038083  0.179733  0.051087  0.000959  0.052355   \n",
      "4  0.056484  0.000551  0.027366  0.156085  0.073481  0.015179  0.026794   \n",
      "\n",
      "         S7        S8        S9  ...      S390      S391      S392      S393  \\\n",
      "0  0.017243  0.000000  0.003856  ...  0.013926  0.001387  0.000221  0.096645   \n",
      "1  0.014330  0.000426  0.033317  ...  0.017063  0.003254  0.003020  0.068192   \n",
      "2  0.036323  0.000863  0.018699  ...  0.021212  0.007629  0.002187  0.070927   \n",
      "3  0.002350  0.001508  0.014987  ...  0.015350  0.008165  0.000509  0.023601   \n",
      "4  0.016925  0.003840  0.064901  ...  0.017797  0.012577  0.004447  0.046960   \n",
      "\n",
      "       S394      S395      S396      S397      S398  S399  \n",
      "0  0.000000  0.057753  0.008783  0.000000  0.018642   0.0  \n",
      "1  0.000584  0.046412  0.000792  0.000000  0.004823   0.0  \n",
      "2  0.000000  0.095508  0.016468  0.000655  0.009779   0.0  \n",
      "3  0.000000  0.020899  0.135187  0.000000  0.024202   0.0  \n",
      "4  0.000000  0.023818  0.062782  0.000000  0.019159   0.0  \n",
      "\n",
      "[5 rows x 400 columns]\n",
      "(834,)\n",
      "0    P001\n",
      "1    P003\n",
      "2    P000\n",
      "3    P000\n",
      "4    P000\n",
      "Name: target, dtype: object\n"
     ]
    }
   ],
   "source": [
    "s_train_df = pd.read_csv(s_trn_file_path, index_col='Unnamed: 0')\n",
    "s_train_df.drop(['name'], axis=1, inplace=True )\n",
    "\n",
    "train_df = s_train_df\n",
    "train_df.target.fillna('P000', inplace=True)\n",
    "train_df.fillna(0.0, inplace=True)\n",
    "\n",
    "##\n",
    "\n",
    "### tf_idf conversion\n",
    "\n",
    "# 1. Save target column, and drop if from dataframe\n",
    "train_df_target = pd.DataFrame(train_df['target'], columns=['target'])\n",
    "train_df.drop(['target'], axis=1, inplace=True )\n",
    "\n",
    "# 2. Replace frequencies with tf_idf scores\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(train_df)\n",
    "X_train_tf = tf_transformer.transform(train_df)\n",
    "train_df = pd.DataFrame(X_train_tf.todense(), columns=train_df.columns.values)\n",
    "\n",
    "# 3. Add back the target column\n",
    "train_df = pd.concat([train_df, train_df_target], axis=1)\n",
    "\n",
    "##\n",
    "\n",
    "s_test_df = pd.read_csv(s_val_file_path, index_col='Unnamed: 0')\n",
    "s_test_df.drop(['name'], axis=1, inplace=True )\n",
    "\n",
    "test_df = s_test_df\n",
    "test_df.target.fillna('P000', inplace=True)\n",
    "test_df.fillna(0.0, inplace=True)\n",
    "\n",
    "##\n",
    "\n",
    "### tf_idf conversion\n",
    "\n",
    "# 1. Save target column, and drop if from dataframe\n",
    "test_df_target = pd.DataFrame(test_df['target'], columns=['target'])\n",
    "test_df.drop(['target'], axis=1, inplace=True )\n",
    "\n",
    "# 2. Replace frequencies with tf_idf scores\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(test_df)\n",
    "X_train_tf = tf_transformer.transform(test_df)\n",
    "test_df = pd.DataFrame(X_train_tf.todense(), columns=test_df.columns.values)\n",
    "\n",
    "# 3. Add back the target column\n",
    "test_df = pd.concat([test_df, test_df_target], axis=1)\n",
    "\n",
    "##\n",
    "\n",
    "# Machine Learning\n",
    "prediction_var = list(train_df.columns)\n",
    "prediction_var.remove('target')\n",
    "\n",
    "# Get input training data\n",
    "train_X = train_df[prediction_var]\n",
    "\n",
    "# Get input target variable\n",
    "train_y = train_df.target\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_X.head())\n",
    "print(train_y.shape)\n",
    "print(train_y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 400)\n",
      "         S0        S1        S2        S3        S4        S5        S6  \\\n",
      "0  0.009888  0.004123  0.116588  0.094998  0.066686  0.007710  0.055892   \n",
      "1  0.022243  0.002129  0.154429  0.055656  0.058430  0.008530  0.102337   \n",
      "2  0.029053  0.003213  0.126304  0.172730  0.069670  0.003825  0.029915   \n",
      "3  0.008119  0.007272  0.058020  0.025384  0.054530  0.002960  0.186647   \n",
      "4  0.002420  0.022335  0.121208  0.031558  0.021832  0.001323  0.081232   \n",
      "\n",
      "         S7        S8        S9  ...      S390      S391      S392      S393  \\\n",
      "0  0.024954  0.001430  0.270837  ...  0.009074  0.006835  0.001013  0.049247   \n",
      "1  0.008162  0.002173  0.008829  ...  0.007937  0.013315  0.009805  0.028784   \n",
      "2  0.007535  0.003086  0.025696  ...  0.004491  0.006194  0.002209  0.054789   \n",
      "3  0.013849  0.003880  0.053611  ...  0.015061  0.002967  0.003969  0.092107   \n",
      "4  0.016293  0.000289  0.017291  ...  0.011558  0.001658  0.000473  0.093540   \n",
      "\n",
      "       S394      S395      S396      S397      S398  S399  \n",
      "0  0.000228  0.028479  0.059029  0.000397  0.027198   0.0  \n",
      "1  0.000000  0.045146  0.013424  0.000368  0.020066   0.0  \n",
      "2  0.000000  0.022492  0.045260  0.000445  0.015347   0.0  \n",
      "3  0.000000  0.084129  0.011750  0.001119  0.017407   0.0  \n",
      "4  0.000000  0.038745  0.007497  0.000167  0.049399   0.0  \n",
      "\n",
      "[5 rows x 400 columns]\n",
      "(398,)\n",
      "0    P002\n",
      "1    P000\n",
      "2    P000\n",
      "3    P001\n",
      "4    P001\n",
      "Name: target, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Machine Learning\n",
    "prediction_var = list(test_df.columns)\n",
    "prediction_var.remove('target')\n",
    "\n",
    "# Get test data feature\n",
    "test_X = test_df[prediction_var]\n",
    "\n",
    "# Get test data target\n",
    "test_y = test_df.target\n",
    "\n",
    "print(test_X.shape)\n",
    "print(test_X.head())\n",
    "print(test_y.shape)\n",
    "print(test_y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.svm.classes.SVC'> [0.         0.13407821 0.36734694 0.16814159]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "my_dict = {'P000':0.0000001, 'P001': 97, 'P002': 24, 'P003': 44}\n",
    "\n",
    "classifiers = [\n",
    "    svm.SVC(gamma='scale', class_weight=my_dict,decision_function_shape = 'ovr', kernel='rbf'),\n",
    "]\n",
    "\n",
    "for model in classifiers:\n",
    "    clf = model\n",
    "\n",
    "    # Fit the model to training\n",
    "    clf.fit(train_X,train_y)\n",
    "\n",
    "    # Check prediction accuracy\n",
    "    prediction = clf.predict(test_X)\n",
    "    print(type(clf), metrics.f1_score(prediction,test_y,average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P001 & 0.2867\n",
      "P002 & 0.3892\n",
      "P003 & 0.0917\n"
     ]
    }
   ],
   "source": [
    "# Get average precision scores\n",
    "\n",
    "clf = svm.SVC(gamma='scale', probability=True, class_weight=my_dict,decision_function_shape = 'ovr')\n",
    "\n",
    "# Fit the model to training\n",
    "clf.fit(train_X,train_y)\n",
    "\n",
    "# Check prediction accuracy\n",
    "prediction = clf.decision_function(test_X)\n",
    "\n",
    "prob_list = prediction[:,1]\n",
    "x = np.array([test_y == 'P001'][0]).astype(int)\n",
    "print('P001 &', round(average_precision_score(x,prob_list, pos_label=1),4))\n",
    "\n",
    "prob_list = prediction[:,2]\n",
    "x = np.array([test_y == 'P002'][0]).astype(int)\n",
    "print('P002 &', round(average_precision_score(x,prob_list, pos_label=1),4))\n",
    "\n",
    "prob_list = prediction[:,3]\n",
    "x = np.array([test_y == 'P003'][0]).astype(int)\n",
    "print('P003 &', round(average_precision_score(x,prob_list, pos_label=1),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
